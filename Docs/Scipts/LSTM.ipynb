{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yP5w-tzX8Wk-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from keras import Sequential\n",
        "from keras.src.layers import LSTM, Dense\n",
        "from sklearn.externals import joblib # ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Teb2Icf98gYo"
      },
      "outputs": [],
      "source": [
        "def get_df(data_size:int=500, path:str=\"..\\Data\\AAPL_stock_prices.csv\", delimeter: str = ',', from_end: bool = True, date_column: str = 'Date', target_column: str = 'Close') -> tuple[np.ndarray, MinMaxScaler, int]:\n",
        "    df = pd.read_csv(path, delimiter=delimeter)\n",
        "    df = df.iloc[-data_size:, :] if from_end else df.iloc[:data_size, :]\n",
        "    dates = pd.to_datetime(df[date_column])\n",
        "    df.drop(columns=[date_column], inplace=True)\n",
        "    df.index = dates\n",
        "    target_column_index = df.columns.tolist().index(target_column)\n",
        "\n",
        "    try: \n",
        "        scaler = joblib.load('scaler.gz')\n",
        "    except:\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "    return scaled_data, scaler, target_column_index\n",
        "\n",
        "scaled_data, scaler, target_column_index = get_df()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_df(df: pd.DataFrame, scaler: MinMaxScaler = None, target_column: str = 'Close'):\n",
        "    target_column_index = df.columns.tolist().index(target_column)\n",
        "    if scaler is None:\n",
        "        try: \n",
        "            scaler = joblib.load('scaler.gz')\n",
        "        except:\n",
        "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "    return scaled_data, target_column_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdppuR7Vg2QP",
        "outputId": "508aaf24-30b9-4b03-81d0-37da7e6a7687"
      },
      "outputs": [],
      "source": [
        "def create_dataset(data: np.ndarray, time_step: int=10):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        # Define the range of input sequences\n",
        "        end_ix = i + time_step\n",
        "        \n",
        "        # Define the range of output sequences\n",
        "        out_end_ix = end_ix + 1\n",
        "        \n",
        "        # Ensure that the dataset is within bounds\n",
        "        if out_end_ix > len(data)-1:\n",
        "            break\n",
        "            \n",
        "        # Extract input and output parts of the pattern\n",
        "        seq_x, seq_y = data[i:end_ix], data[out_end_ix]\n",
        "        \n",
        "        # Append the parts\n",
        "        X.append(seq_x)\n",
        "        Y.append(seq_y)\n",
        "    return np.array(X), np.array(Y), data.shape[1], time_step\n",
        "\n",
        "\n",
        "X, Y, feature_number, time_step = create_dataset(data=scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Qwa_jXUyO9pU",
        "outputId": "c1054b8e-b3f6-47e2-864a-2884c5ab727a"
      },
      "outputs": [],
      "source": [
        "# Plot X and Y\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "for i in range(250,251):\n",
        "    plot_X, plot_all = [], []\n",
        "    for value in range(X.shape[1]):\n",
        "      plot_X.append(X[i, value, target_column_index])\n",
        "      plot_all.append(X[i, value, target_column_index])\n",
        "    plot_all.append(Y[i, target_column_index])\n",
        "\n",
        "    plt.figure(figsize=(13, 5))\n",
        "    plt.plot(plot_all, label='Y')\n",
        "    plt.plot(plot_X, label='X')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFRNbsyTMqr7",
        "outputId": "f4c245e2-2b15-47ce-f3d3-c9ea4b2e9c8e"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(len(X) * 0.7)\n",
        "test_size = len(X) - train_size\n",
        "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
        "Y_train, Y_test = Y[0:train_size], Y[train_size:len(Y)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{X_train.shape=}, {Y_train.shape=}\")\n",
        "print(f\"{X_test.shape=}, {Y_test.shape=}\")\n",
        "print(X_train[:1, 0, :])\n",
        "print(X_test[:1, 0, :])\n",
        "print(Y_train[:1, :])\n",
        "print(Y_test[:1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EoBx1hL58s34"
      },
      "outputs": [],
      "source": [
        "def create_model(input_shape: tuple, layers_with_units: list[int] = [128,128,64], optimizer: str = 'adam', loss: str = 'mean_squared_error', metrics: list[str]=['mse', 'mape']) -> Sequential:\n",
        "    # Create the LSTM model\n",
        "    model = Sequential()\n",
        "    for layer in layers_with_units[:-1]:\n",
        "        model.add(LSTM(layer, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(LSTM(layers_with_units[-1], return_sequences=False))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer = optimizer, loss = loss, metrics=metrics)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCH: int = 20\n",
        "BATCH_SIZE: int = 1\n",
        "LAYERS: list[int] = [128,128,64]\n",
        "OPTIMIZER: str = 'adam'\n",
        "LOSS: str = 'mean_squared_error'\n",
        "METRICS: list[str] = ['mse', 'mape']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_model(input_shape=(X_train.shape[1], feature_number), layers_with_units=LAYERS, optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrdF2tLCXQko",
        "outputId": "792c5289-5bb3-454d-a898-d73e71a87d59"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=EPOCH, batch_size=BATCH_SIZE, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "hlpCV0PjASRl",
        "outputId": "ed20524d-6ead-4c79-b2e9-bbedd5b0360b"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation loss values\n",
        "print(history.history.keys())\n",
        "other_keys: list = []\n",
        "for value in history.history.keys() :\n",
        "    plt.plot(history.history[value], label=value.replace('_', ' ').capitalize()) if not 'loss' in value and not 'acc' in value else other_keys.append(value)\n",
        "    plt.title('Errors')\n",
        "    plt.ylabel(value.replace('_', ' ').capitalize())\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "for value in other_keys :\n",
        "    plt.plot(history.history[value], label=value.replace('_', ' ').capitalize())\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel(value.replace('_', ' ').capitalize())\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py4kqKXs8ySk",
        "outputId": "74dba196-9de7-4a9f-febb-506492cff7af"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpPCFgKkWYd7",
        "outputId": "1c4809f3-deb9-4b09-ced8-88e7ae1e5873"
      },
      "outputs": [],
      "source": [
        "print(f\"{train_predict.shape=}, {test_predict.shape=}, {Y_train.shape=}, {Y_test.shape=}\")\n",
        "# print(train_predict[:2, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inverse transform the predictions\n",
        "def update_data_to_inverse(predicted_data: np.ndarray, scaler: MinMaxScaler, target_column_index: int, feature_number: int):\n",
        "    new_dataset = np.zeros(shape=(len(predicted_data), feature_number))\n",
        "    new_dataset[:,target_column_index] = predicted_data.flatten()\n",
        "    return scaler.inverse_transform(new_dataset)[:, target_column_index].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_predict = update_data_to_inverse(predicted_data=train_predict, scaler=scaler, target_column_index=target_column_index, feature_number=feature_number)\n",
        "test_predict = update_data_to_inverse(predicted_data=test_predict, scaler=scaler, target_column_index=target_column_index, feature_number=feature_number)\n",
        "Y_train = scaler.inverse_transform(Y_train)\n",
        "Y_test = scaler.inverse_transform(Y_test)\n",
        "\n",
        "print(f\"{train_predict.shape=}, {test_predict.shape=}, {Y_train.shape=}, {Y_test.shape=}\")\n",
        "print(train_predict[:2, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EAsNl-hV3Hk",
        "outputId": "967c936f-cecc-4a66-9801-13bd6b4ed227"
      },
      "outputs": [],
      "source": [
        "# Calculate MSE\n",
        "train_mse = mean_squared_error(Y_train[:, target_column_index].reshape(-1, 1), train_predict)\n",
        "test_mse = mean_squared_error(Y_test[:, target_column_index].reshape(-1, 1), test_predict)\n",
        "\n",
        "# Calculate R2 score\n",
        "train_r2 = r2_score(Y_train[:, target_column_index].reshape(-1, 1), train_predict)\n",
        "test_r2 = r2_score(Y_test[:, target_column_index].reshape(-1, 1), test_predict)\n",
        "\n",
        "print(f\"Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
        "print(f\"Train R2 Score: {train_r2:.4f}, Test R2 Score: {test_r2:.4f}\")\n",
        "print(f\"\\nTrue - Y_train[5:10, target_column_index].reshape(-1, 1)\\n{Y_train[5:10, target_column_index].reshape(-1, 1)}\\n\\nPredicted - train_predict[5:10]\\n{train_predict[5:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log(epoch, layers_with_units, optimizer, loss, train_mse = None, train_r2 = None, y_true = None, train_predict = None):\n",
        "    with open('log.txt', 'a') as file:\n",
        "        file.write(f\"Train Results with Epoch - {epoch}:\")\n",
        "        if y_true and train_predict:\n",
        "            file.write(f\"\\nY_True:\\n{y_true}\\nY_Predicted\\n{train_predict}\")        \n",
        "        file.write(f\"\\n    Layers: {layers_with_units}\")\n",
        "        file.write(f\"\\n    Optimizer : {optimizer}\")\n",
        "        file.write(f\"\\n    Loss: {loss}\")\n",
        "        file.write(f\"\\n    Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
        "        file.write(f\"\\n    Train R2 Score: {train_r2:.4f}, Test R2 Score: {test_r2:.4f}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# log(epoch=EPOCH, layers_with_units=LAYERS, optimizer=OPTIMIZER, loss=LOSS, train_mse=train_mse, train_r2=train_r2, y_true=Y_train[5:10, target_column_index].reshape(-1, 1), train_predict=train_predict[5:10])\n",
        "log(epoch=EPOCH, layers_with_units=LAYERS, optimizer=OPTIMIZER, loss=LOSS, train_mse=train_mse, train_r2=train_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "LM9Q4Qq288H4",
        "outputId": "a337eadc-54f1-40df-fb9f-0c93b4c4b04a"
      },
      "outputs": [],
      "source": [
        "print(f\"{time_step=}, {X.shape=}, {(len(train_predict) + time_step)=}\")\n",
        "print(f\"{test_predict.shape=}, {train_predict.shape=}, {scaled_data.shape=}\")\n",
        "\n",
        "# Plot the predictions\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(scaler.inverse_transform(scaled_data)[:, target_column_index], label='Original Data')\n",
        "train_predict_plot = np.empty_like(scaled_data[:, target_column_index]).reshape(-1, 1)\n",
        "train_predict_plot[:, :] = np.nan\n",
        "train_predict_plot[time_step:len(train_predict) + time_step, :] = train_predict\n",
        "plt.plot(train_predict_plot, label='Training Predictions')\n",
        "\n",
        "test_predict_plot = np.empty_like(scaled_data[:, target_column_index]).reshape(-1, 1)\n",
        "test_predict_plot[:, :] = np.nan\n",
        "test_predict_plot[len(train_predict) + time_step:len(scaled_data[:, target_column_index]) - 1, :] = test_predict\n",
        "plt.plot(test_predict_plot, label='Testing Predictions')\n",
        "\n",
        "plt.title('Time Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(scaler, 'scaler.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EfF2C6c7BDZ",
        "outputId": "18fa039c-a0ad-429f-cbd1-dc31d314eaae"
      },
      "outputs": [],
      "source": [
        "model.save('lstm_model_test.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yjcrN7s7HPM"
      },
      "outputs": [],
      "source": [
        "# # Load the saved model\n",
        "# loaded_model = load_model('lstm_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQKAidWG7RI6"
      },
      "outputs": [],
      "source": [
        "# # Assuming `X_new` and `Y_new` are new data arrays\n",
        "# history_updated = loaded_model.fit(X_new, Y_new, epochs=50, batch_size=1, verbose=1)\n",
        "\n",
        "# # Save the updated model\n",
        "# loaded_model.save('updated_lstm_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
