{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yP5w-tzX8Wk-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "data_size = 2000\n",
        "target_column_index = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Teb2Icf98gYo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "[[0.00479132 0.00544348 0.00552764 0.00501143 0.00456758 0.21899013]\n",
            " [0.00434795 0.00459294 0.00538406 0.00579668 0.0052833  0.24749836]]\n",
            "                 Open       High      Low      Close  Adj Close     Volume\n",
            "Date                                                                      \n",
            "2016-06-22  24.062500  24.222500  23.8375  23.887501  21.940348  116876400\n",
            "2016-06-23  23.985001  24.072500  23.8125  24.025000  22.066641  128960800\n",
            "2016-06-24  23.227501  23.665001  23.1625  23.350000  21.446665  301245600\n",
            "2016-06-27  23.250000  23.262501  22.8750  23.010000  21.134375  181958400\n",
            "2016-06-28  23.225000  23.415001  23.0350  23.397499  21.490294  161779600\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('..\\Data\\eurusd_hour.csv', delimiter=',')\n",
        "df = df.iloc[:data_size, :]\n",
        "dates = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df.drop(columns=['Date', 'Time'], inplace=True)\n",
        "df.index = dates\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "print(scaled_data[:10, :])\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdppuR7Vg2QP",
        "outputId": "508aaf24-30b9-4b03-81d0-37da7e6a7687"
      },
      "outputs": [],
      "source": [
        "# def create_dataset(data: np.ndarray, time_step: int=10):\n",
        "#     feature_number = data.shape[1]\n",
        "#     Y = []\n",
        "#     X = np.full((len(range(time_step, len(data) - 1)), time_step, feature_number), np.nan, dtype=float)\n",
        "#     print(X.shape)\n",
        "#     for i in range(time_step, len(data) - 1):\n",
        "#         window = data[i - time_step : i, 0]\n",
        "\n",
        "#         X[i - time_step, :, 0] = window.flatten()\n",
        "\n",
        "#         Y.append(data[i, 0])\n",
        "        \n",
        "#     return X, np.array(Y, dtype=float).reshape(-1, 1), feature_number, time_step\n",
        "\n",
        "def create_dataset(data: np.ndarray, time_step: int=10):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        # Define the range of input sequences\n",
        "        end_ix = i + time_step\n",
        "        \n",
        "        # Define the range of output sequences\n",
        "        out_end_ix = end_ix + 1\n",
        "        \n",
        "        # Ensure that the dataset is within bounds\n",
        "        if out_end_ix > len(data)-1:\n",
        "            break\n",
        "            \n",
        "        # Extract input and output parts of the pattern\n",
        "        seq_x, seq_y = data[i:end_ix], data[out_end_ix]\n",
        "        \n",
        "        # Append the parts\n",
        "        X.append(seq_x)\n",
        "        Y.append(seq_y)\n",
        "    return np.array(X), np.array(Y), data.shape[1], time_step\n",
        "\n",
        "\n",
        "X, Y, feature_number, time_step = create_dataset(data=scaled_data)\n",
        "\n",
        "print(type(X), type(Y), feature_number, time_step, sep=' ')\n",
        "print(X.shape, Y.shape)\n",
        "print(f\"X:\\n{X[:1, :]=}\\nY:\\n{Y[:1]=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Qwa_jXUyO9pU",
        "outputId": "c1054b8e-b3f6-47e2-864a-2884c5ab727a"
      },
      "outputs": [],
      "source": [
        "# Plot X and Y\n",
        "print(X.shape)\n",
        "for i in range(100,121, 7):\n",
        "    plot_X, plot_all = [], []\n",
        "    for value in range(X.shape[1]):\n",
        "      plot_X.append(X[i, value, target_column_index])\n",
        "      plot_all.append(X[i, value, target_column_index])\n",
        "    plot_all.append(Y[i, target_column_index])\n",
        "\n",
        "    plt.figure(figsize=(13, 5))\n",
        "    plt.plot(plot_all, label='Y')\n",
        "    plt.plot(plot_X, label='X')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFRNbsyTMqr7",
        "outputId": "f4c245e2-2b15-47ce-f3d3-c9ea4b2e9c8e"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(len(X) * 0.7)\n",
        "test_size = len(X) - train_size\n",
        "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
        "Y_train, Y_test = Y[0:train_size], Y[train_size:len(Y)]\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EoBx1hL58s34"
      },
      "outputs": [],
      "source": [
        "# Create the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], feature_number)))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrdF2tLCXQko",
        "outputId": "792c5289-5bb3-454d-a898-d73e71a87d59"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5, batch_size=1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "hlpCV0PjASRl",
        "outputId": "ed20524d-6ead-4c79-b2e9-bbedd5b0360b"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation loss values\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Value Loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py4kqKXs8ySk",
        "outputId": "74dba196-9de7-4a9f-febb-506492cff7af"
      },
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpPCFgKkWYd7",
        "outputId": "1c4809f3-deb9-4b09-ced8-88e7ae1e5873"
      },
      "outputs": [],
      "source": [
        "print(f\"{train_predict.shape=}, {test_predict.shape=}, {Y_train.shape=}, {Y_test.shape=}\")\n",
        "print(train_predict[:2, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inverse transform the predictions\n",
        "def update_data_to_inverse(predicted_data: np.ndarray, scaler: MinMaxScaler, target_column_index: int):\n",
        "    new_dataset = np.zeros(shape=(len(predicted_data), feature_number))\n",
        "    new_dataset[:,target_column_index] = predicted_data.flatten()\n",
        "    return scaler.inverse_transform(new_dataset)[:, target_column_index].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_predict = update_data_to_inverse(predicted_data=train_predict, scaler=scaler, target_column_index=target_column_index)\n",
        "test_predict = update_data_to_inverse(predicted_data=test_predict, scaler=scaler, target_column_index=target_column_index)\n",
        "Y_train = scaler.inverse_transform(Y_train)\n",
        "Y_test = scaler.inverse_transform(Y_test)\n",
        "\n",
        "print(f\"{train_predict.shape=}, {test_predict.shape=}, {Y_train.shape=}, {Y_test.shape=}\")\n",
        "print(train_predict[:2, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EAsNl-hV3Hk",
        "outputId": "967c936f-cecc-4a66-9801-13bd6b4ed227"
      },
      "outputs": [],
      "source": [
        "# Calculate MSE\n",
        "train_mse = mean_squared_error(Y_train[:, target_column_index].reshape(-1, 1), train_predict)\n",
        "test_mse = mean_squared_error(Y_test[:, target_column_index].reshape(-1, 1), test_predict)\n",
        "\n",
        "# Calculate R2 score\n",
        "train_r2 = r2_score(Y_train[:, target_column_index].reshape(-1, 1), train_predict)\n",
        "test_r2 = r2_score(Y_test[:, target_column_index].reshape(-1, 1), test_predict)\n",
        "\n",
        "print(f\"Train MSE: {train_mse:.4f}, Test MSE: {test_mse:.4f}\")\n",
        "print(f\"Train R2 Score: {train_r2:.4f}, Test R2 Score: {test_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "LM9Q4Qq288H4",
        "outputId": "a337eadc-54f1-40df-fb9f-0c93b4c4b04a"
      },
      "outputs": [],
      "source": [
        "print(f\"{time_step=}, {X.shape=}, {(len(train_predict) + time_step)=}\")\n",
        "print(f\"{test_predict.shape=}, {train_predict.shape=}, {scaled_data.shape=}\")\n",
        "\n",
        "# Plot the predictions\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(scaler.inverse_transform(scaled_data)[:, target_column_index], label='Original Data')\n",
        "train_predict_plot = np.empty_like(scaled_data[:, target_column_index]).reshape(-1, 1)\n",
        "train_predict_plot[:, :] = np.nan\n",
        "train_predict_plot[time_step:len(train_predict) + time_step, :] = train_predict\n",
        "plt.plot(train_predict_plot, label='Training Predictions')\n",
        "\n",
        "test_predict_plot = np.empty_like(scaled_data[:, target_column_index]).reshape(-1, 1)\n",
        "test_predict_plot[:, :] = np.nan\n",
        "test_predict_plot[len(train_predict) + time_step:len(scaled_data[:, target_column_index]) - 1, :] = test_predict\n",
        "plt.plot(test_predict_plot, label='Testing Predictions')\n",
        "\n",
        "plt.title('Time Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EfF2C6c7BDZ",
        "outputId": "18fa039c-a0ad-429f-cbd1-dc31d314eaae"
      },
      "outputs": [],
      "source": [
        "model.save('lstm_model_test.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yjcrN7s7HPM"
      },
      "outputs": [],
      "source": [
        "# # Load the saved model\n",
        "# loaded_model = load_model('lstm_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQKAidWG7RI6"
      },
      "outputs": [],
      "source": [
        "# # Assuming `X_new` and `Y_new` are new data arrays\n",
        "# history_updated = loaded_model.fit(X_new, Y_new, epochs=50, batch_size=1, verbose=1)\n",
        "\n",
        "# # Save the updated model\n",
        "# loaded_model.save('updated_lstm_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
