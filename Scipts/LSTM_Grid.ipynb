{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yP5w-tzX8Wk-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from keras import Sequential\n",
        "from keras.src.layers import LSTM, Dense\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Teb2Icf98gYo"
      },
      "outputs": [],
      "source": [
        "def get_df(data_size:int=500, path:str=\"..\\Data\\AAPL_stock_prices.csv\", delimeter: str = ',', from_end: bool = True, date_column: str = 'Date', target_column: str = 'Close') -> tuple[np.ndarray, MinMaxScaler, int]:\n",
        "    df = pd.read_csv(path, delimiter=delimeter)\n",
        "    df = df.iloc[-data_size:, :] if from_end else df.iloc[:data_size, :]\n",
        "    dates = pd.to_datetime(df[date_column])\n",
        "    df.drop(columns=[date_column], inplace=True)\n",
        "    df.index = dates\n",
        "\n",
        "    target_column_index = df.columns.tolist().index(target_column)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "    return scaled_data, scaler, target_column_index\n",
        "\n",
        "scaled_data, scaler, target_column_index = get_df()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdppuR7Vg2QP",
        "outputId": "508aaf24-30b9-4b03-81d0-37da7e6a7687"
      },
      "outputs": [],
      "source": [
        "def create_dataset(data: np.ndarray, time_step: int=10):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        # Define the range of input sequences\n",
        "        end_ix = i + time_step\n",
        "        \n",
        "        # Define the range of output sequences\n",
        "        out_end_ix = end_ix + 1\n",
        "        \n",
        "        # Ensure that the dataset is within bounds\n",
        "        if out_end_ix > len(data)-1:\n",
        "            break\n",
        "            \n",
        "        # Extract input and output parts of the pattern\n",
        "        seq_x, seq_y = data[i:end_ix], data[out_end_ix]\n",
        "        \n",
        "        # Append the parts\n",
        "        X.append(seq_x)\n",
        "        Y.append(seq_y)\n",
        "    return np.array(X), np.array(Y), data.shape[1], time_step\n",
        "\n",
        "\n",
        "X, Y, feature_number, time_step = create_dataset(data=scaled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFRNbsyTMqr7",
        "outputId": "f4c245e2-2b15-47ce-f3d3-c9ea4b2e9c8e"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = int(len(X) * 0.7)\n",
        "test_size = len(X) - train_size\n",
        "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
        "Y_train, Y_test = Y[0:train_size], Y[train_size:len(Y)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{X_train.shape=}, {Y_train.shape=}\")\n",
        "print(f\"{X_test.shape=}, {Y_test.shape=}\")\n",
        "print(X_train[:1, 0, :])\n",
        "print(X_test[:1, 0, :])\n",
        "print(Y_train[:1, :])\n",
        "print(Y_test[:1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EoBx1hL58s34"
      },
      "outputs": [],
      "source": [
        "def create_model(unit_one, unit_two, unit_three, unit_four, activation='linear', optimizer: str = 'adam', loss: str = 'mean_squared_error', batch_size=1, epochs=50) -> Sequential:\n",
        "    # Create the LSTM model\n",
        "    metrics: list[str]=['accuracy']\n",
        "    input_shape: tuple = (10,6)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(unit_one, return_sequences=True, input_shape=input_shape, activation=activation))\n",
        "    if unit_two > 0:\n",
        "        model.add(LSTM(unit_two, return_sequences=True, input_shape=input_shape))\n",
        "    if unit_three > 0:\n",
        "        model.add(LSTM(unit_three, return_sequences=True, input_shape=input_shape))        \n",
        "    model.add(LSTM(unit_four, return_sequences=False))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer = optimizer, loss = loss, metrics=metrics)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'model__optimizer': ['RMSprop', 'adam'],\n",
        "    'model__loss': ['mean_squared_error'],\n",
        "    'batch_size': [1, 2],\n",
        "    'epochs': [50],\n",
        "    'model__unit_one': [64, 128, 256],\n",
        "    'model__unit_two': [64, 128],\n",
        "    'model__unit_three': [64, 128],\n",
        "    'model__unit_four': [64],\n",
        "    'model__activation': ['relu', 'tanh', 'sigmoid','linear']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm_regressor = KerasRegressor(model=create_model, verbose=1)\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=lstm_regressor, param_grid=param_grid, scoring='neg_mean_absolute_error', error_score='raise', cv=5)\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, Y_train[:, target_column_index].reshape(-1,1))\n",
        "\n",
        "\n",
        "with open(\"example.txt\", \"w\") as file:\n",
        "    # Write some content to the file\n",
        "    file.write(f\"{grid_search.best_params_=}, {grid_search.best_score_=}\\n\\n\")\n",
        "    file.write(f\"{grid_search.best_estimator_=}\\n\\n\")\n",
        "    file.write(f\"{grid_search.best_index_=}\\n\\n\")\n",
        "    file.write(f\"{grid_search.scorer_=}\\n\\n\")\n",
        "    file.write(f\"{grid_search.cv_results_=}\\n\\n\")\n",
        "\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "print(grid_search.best_score_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
